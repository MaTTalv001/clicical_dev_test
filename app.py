# app.py
"""
ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ã€è‡¨åºŠè©¦é¨“ãƒ‡ãƒ¼ã‚¿ã®æ¤œç´¢ãƒ»åˆ†æãƒ»å¯è¦–åŒ–ã‚’è¡Œã†Streamlitãƒ™ãƒ¼ã‚¹ã®Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã™ã€‚

ä¸»ãªæ©Ÿèƒ½ï¼š
1. PICOå½¢å¼ã§ã®è‡¨åºŠè©¦é¨“æ¤œç´¢
2. æ¤œç´¢çµæœã®æ§‹é€ åŒ–ã¨å¯è¦–åŒ–
3. LLMã‚’ç”¨ã„ãŸçµæœã®åˆ†æã¨è¦ç´„
4. è©¦é¨“ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã®ç”Ÿæˆæ”¯æ´

ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼š
- AWSã®Bedrockï¼ˆClaudeï¼‰ã‚’åˆ©ç”¨ã—ãŸLLMå‡¦ç†
- ClinicalTrials.gov APIã‚’ä½¿ç”¨ã—ãŸãƒ‡ãƒ¼ã‚¿å–å¾—
- Streamlitã«ã‚ˆã‚‹ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹æä¾›
"""

import streamlit as st
import os
import re
import json
import datetime
import boto3
import pandas as pd
import urllib.parse
from langchain_community.chat_models import BedrockChat
from utils.prompts import (
    SYSTEM_PROMPT, USER_PROMPT_TEMPLATE, SUMMARY_PROMPT_TEMPLATE,
    CROSS_STUDY_PROMPT, CRITERIA_PROMPT, PUBLICATION_PROMPT,
    COMPARISON_PROMPT, PROTOCOL_PROMPT)
from utils.utils import get_top_items, convert_df_to_csv
from utils.api_handler import APIHandler
from utils.visualizer import Visualizer

# å®šæ•°ã¨ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®š
st.set_page_config(page_title="Clinical Trials Search and Analysis App", layout="wide")

# AWSã®èªè¨¼æƒ…å ±ã®è¨­å®š
os.environ['AWS_ACCESS_KEY_ID'] = st.secrets["AWS_ACCESS_KEY_ID"]
os.environ['AWS_SECRET_ACCESS_KEY'] = st.secrets["AWS_SECRET_ACCESS_KEY"]
os.environ['AWS_DEFAULT_REGION'] = st.secrets["AWS_DEFAULT_REGION"]

# ä¸»è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åˆæœŸåŒ–
bedrock = boto3.client('bedrock-runtime')
llm = BedrockChat(model_id="anthropic.claude-3-5-sonnet-20240620-v1:0", client=bedrock)
api_handler = APIHandler("https://clinicaltrials.gov/api/v2/studies")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'structured_studies' not in st.session_state:
    st.session_state.structured_studies = []
if 'selected_studies' not in st.session_state:
    st.session_state.selected_studies = []
if 'search_performed' not in st.session_state:
    st.session_state.search_performed = False
if 'total_count' not in st.session_state:
    st.session_state.total_count = 0
# æ–°ã—ã„ã‚¹ãƒ†ãƒƒãƒ—ã®å®Œäº†çŠ¶æ…‹
if 'summary_generated' not in st.session_state:
    st.session_state.summary_generated = False
if 'criteria_analyzed' not in st.session_state:
    st.session_state.criteria_analyzed = False
if 'publications_summarized' not in st.session_state:
    st.session_state.publications_summarized = False
if 'comparison_analyzed' not in st.session_state:
    st.session_state.comparison_analyzed = False

@st.cache_data
def cached_fetch_and_structure_studies(query):
    """
    APIã‹ã‚‰ã®è‡¨åºŠè©¦é¨“ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã¨æ§‹é€ åŒ–ã‚’è¡Œã„ã€çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹

    @st.cache_dataãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ã«ã‚ˆã‚Š:
    - åŒã˜ã‚¯ã‚¨ãƒªã«å¯¾ã™ã‚‹çµæœãŒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã‚‹
    - ã‚¢ãƒ—ãƒªã®å®Ÿè¡ŒåŠ¹ç‡ãŒå‘ä¸Šã™ã‚‹
    - APIã¸ã®ä¸è¦ãªãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‰Šæ¸›ã§ãã‚‹

    Args:
        query (dict): æ¤œç´¢ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

    Returns:
        tuple: (æ§‹é€ åŒ–ã•ã‚ŒãŸè©¦é¨“ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ, ç·è©¦é¨“æ•°)
    """
    return api_handler.fetch_and_structure_studies(query)

def main():
    """
    APIã‹ã‚‰ã®è‡¨åºŠè©¦é¨“ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã¨æ§‹é€ åŒ–ã‚’è¡Œã„ã€çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹

    @st.cache_dataãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ã«ã‚ˆã‚Š:
    - åŒã˜ã‚¯ã‚¨ãƒªã«å¯¾ã™ã‚‹çµæœãŒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã‚‹
    - ã‚¢ãƒ—ãƒªã®å®Ÿè¡ŒåŠ¹ç‡ãŒå‘ä¸Šã™ã‚‹
    - APIã¸ã®ä¸è¦ãªãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‰Šæ¸›ã§ãã‚‹

    Args:
        query (dict): æ¤œç´¢ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

    Returns:
        tuple: (æ§‹é€ åŒ–ã•ã‚ŒãŸè©¦é¨“ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ, ç·è©¦é¨“æ•°)
    """
    st.title("Clinical Trials Search and Analysis App Î²ç‰ˆ")
    st.markdown("""
        ### ã“ã®ã‚¢ãƒ—ãƒªã§ã§ãã‚‹ã“ã¨
        1. **è‡¨åºŠè©¦é¨“ã®ä½“ç³»çš„ãªæ¤œç´¢**: PICOå½¢å¼ã§ã®æ¡ä»¶æŒ‡å®šã«ã‚ˆã‚Šã€ç›®çš„ã«åˆã£ãŸè‡¨åºŠè©¦é¨“ã‚’æ¤œç´¢
        2. **çµæœã®è‡ªå‹•è¦ç´„**: æ¤œç´¢çµæœã®å‚¾å‘åˆ†æã¨å¯è¦–åŒ–
        3. **å€‹åˆ¥è©¦é¨“ã®è©³ç´°ç¢ºèª**: èˆˆå‘³ã®ã‚ã‚‹è©¦é¨“ã«ã¤ã„ã¦è©³ã—ã„æƒ…å ±ã‚’ç¢ºèª

        #### ä½¿ã„æ–¹
        1. ä¸‹ã®ãƒ•ã‚©ãƒ¼ãƒ ã«æ¤œç´¢æ¡ä»¶ã‚’å…¥åŠ›
        2. å¿…è¦ã«å¿œã˜ã¦è©¦é¨“æœŸé–“ã‚’æŒ‡å®š
        3. ã€Œæ¤œç´¢ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
        
        > ğŸ’¡ **Tip**: æ¤œç´¢çµæœãŒå¤šã™ãã‚‹å ´åˆã¯ã€è©¦é¨“æœŸé–“ã‚„æ¡ä»¶ã‚’ã‚ˆã‚Šå…·ä½“çš„ã«æŒ‡å®šã—ã¦ãã ã•ã„
        """)

    # PICOå…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
    submitted, p, i, c, o, date_ranges, additional = input_pico_form()
    
    
    if submitted:
        query = generate_query(p, i, c, o, date_ranges, additional)
        if query:
            st.session_state.structured_studies, st.session_state.total_count = cached_fetch_and_structure_studies(query)
            st.session_state.search_performed = True
        
    if st.session_state.search_performed:
        # çµæœã®è¡¨ç¤º
        display_results(st.session_state.structured_studies, st.session_state.total_count)
        
        # çµæœã®è¦ç´„ã¨å¯è¦–åŒ–
        if st.button("çµæœã®è¦ç´„ã¨å¯è¦–åŒ–ã‚’å®Ÿè¡Œ"):
            analyze_studies(st.session_state.structured_studies, p)
            st.session_state.summary_generated = True
        
        # é©æ ¼åŸºæº–ã®è©³ç´°åˆ†æ
        if st.session_state.summary_generated:
            if st.button("é©æ ¼åŸºæº–ã®è©³ç´°åˆ†æã‚’å®Ÿè¡Œ"):
                analyze_eligibility_criteria(st.session_state.structured_studies)
                st.session_state.criteria_analyzed = True
        
        # é–¢é€£æ–‡çŒ®ã®è¦ç´„
        if st.session_state.criteria_analyzed:
            if st.button("é–¢é€£æ–‡çŒ®ã®è¦ç´„ã‚’å®Ÿè¡Œ"):
                summarize_publications(st.session_state.structured_studies)
                st.session_state.publications_summarized = True
        
        # è¤‡æ•°ã®è©¦é¨“ã®æ¨ªæ–­çš„ãªæ¯”è¼ƒåˆ†æ
        if st.session_state.publications_summarized:
            if st.button("è©¦é¨“ã®æ¯”è¼ƒåˆ†æã‚’å®Ÿè¡Œ"):
                compare_studies(st.session_state.structured_studies)
                st.session_state.comparison_analyzed = True
        
        # ãƒ—ãƒ­ãƒˆã‚³ãƒ«ãƒ‰ãƒ©ãƒ•ãƒˆç”Ÿæˆæ”¯æ´
        if st.session_state.comparison_analyzed:
            generate_protocol_draft(st.session_state.structured_studies)

def input_pico_form():
   """PICOå½¢å¼ã§ã®å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã‚’æä¾›"""
   with st.form(key='pico_form'):
       p = st.text_input("Patient (å¯¾è±¡æ‚£è€…):", key='p')
       i = st.text_input("Intervention (ä»‹å…¥):", key='i')
       c = st.text_input("Comparison (æ¯”è¼ƒå¯¾è±¡):", key='c')
       o = st.text_input("Outcome (çµæœ):", key='o')
       
       # è©¦é¨“é–‹å§‹æœŸé–“
       st.write("è©¦é¨“é–‹å§‹æœŸé–“")
       start_cols = st.columns(2)
       with start_cols[0]:
           start_date_min = st.date_input(
               "é–‹å§‹æ—¥ï¼ˆFromï¼‰",
               value=datetime.date(2010, 1, 1),
               min_value=datetime.date(2000, 1, 1),
               max_value=datetime.date.today(),
               key='start_date_min'
           )
       with start_cols[1]:
           start_date_max = st.date_input(
               "é–‹å§‹æ—¥ï¼ˆToï¼‰",
               value=datetime.date(2018, 12, 31),
               min_value=datetime.date(2000, 1, 1),
               max_value=datetime.date.today(),
               key='start_date_max'
           )
       
       # è©¦é¨“å®Œäº†æœŸé–“
       st.write("è©¦é¨“å®Œäº†æœŸé–“")
       end_cols = st.columns(2)
       with end_cols[0]:
           end_date_min = st.date_input(
               "å®Œäº†æ—¥ï¼ˆFromï¼‰",
               value=datetime.date(2010, 1, 1),
               min_value=datetime.date(2000, 1, 1),
               max_value=datetime.date.today(),
               key='end_date_min'
           )
       with end_cols[1]:
           end_date_max = st.date_input(
               "å®Œäº†æ—¥ï¼ˆToï¼‰",
               value=datetime.date(2018, 12, 31),
               min_value=datetime.date(2000, 1, 1),
               max_value=datetime.date.today(),
               key='end_date_max'
           )

       additional = st.text_input("Additional conditions (ãã®ä»–ã®è¿½åŠ æ¡ä»¶):", key='additional')
       submitted = st.form_submit_button(label='æ¤œç´¢')
       
   return submitted, p, i, c, o, {
       'start_date_range': (start_date_min, start_date_max),
       'end_date_range': (end_date_min, end_date_max)
   }, additional

def generate_query(p, i, c, o, date_ranges, additional):
    """LLMã‚’ä½¿ç”¨ã—ã¦æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆ"""
    user_prompt = USER_PROMPT_TEMPLATE.format(p=p, i=i, c=c, o=o, additional=additional)
    
    with st.spinner("ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆä¸­..."):
        response = llm.invoke(SYSTEM_PROMPT + "\n" + user_prompt)

    st.subheader("ç”Ÿæˆã•ã‚ŒãŸã‚¯ã‚¨ãƒª:")
    st.code(response.content, language='json')

    try:
        query = json.loads(response.content)
        
        # æ—¥ä»˜ç¯„å›²ã‚’è¿½åŠ 
        start_min, start_max = date_ranges['start_date_range']
        end_min, end_max = date_ranges['end_date_range']
        
        # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®æ§‹ç¯‰
        date_filters = []
        if start_min and start_max:  # é–‹å§‹æ—¥ç¯„å›²ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆ
            date_filters.append(f"AREA[StartDate]RANGE[{start_min.strftime('%Y-%m-%d')},{start_max.strftime('%Y-%m-%d')}]")
        if end_min and end_max:      # å®Œäº†æ—¥ç¯„å›²ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆ
            date_filters.append(f"AREA[CompletionDate]RANGE[{end_min.strftime('%Y-%m-%d')},{end_max.strftime('%Y-%m-%d')}]")
        
        # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãŒã‚ã‚‹å ´åˆã¯advancedãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã«è¿½åŠ 
        if date_filters:
            query['filter.advanced'] = " AND ".join(date_filters)

        st.success("ã‚¯ã‚¨ãƒªã®ãƒ‘ãƒ¼ã‚¹ã«æˆåŠŸã—ã¾ã—ãŸã€‚")
        
        # clinicaltrials.govã®URLã‚’ç”Ÿæˆ
        ct_gov_url = create_clinicaltrials_gov_url(query)
        
        # ãƒªãƒ³ã‚¯ãƒœã‚¿ãƒ³ã‚’ä½œæˆ
        st.markdown(f"[ClinicalTrials.govã§ç¢ºèªã™ã‚‹]({ct_gov_url})")
        
        return query
    except json.JSONDecodeError:
        st.error("ç”Ÿæˆã•ã‚ŒãŸã‚¯ã‚¨ãƒªãŒæ­£ã—ã„JSONå½¢å¼ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        return None
    
def create_clinicaltrials_gov_url(query):
    """
    APIã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‹ã‚‰ClinicalTrials.govã®æ¤œç´¢URLã‚’ç”Ÿæˆã™ã‚‹

    Args:
        query (dict): APIã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å«ã‚€è¾æ›¸

    Returns:
        str: ClinicalTrials.govã®æ¤œç´¢URL
    """
    base_url = "https://clinicaltrials.gov/search?"
    params = {'viewType': 'Table'}  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
    
    # ç–¾æ‚£ãƒ»çŠ¶æ…‹ã®æ¤œç´¢æ¡ä»¶
    if 'query.cond' in query:
        params['cond'] = query['query.cond']
    
    # ä»‹å…¥æ–¹æ³•ã®æ¤œç´¢æ¡ä»¶
    if 'query.intr' in query:
        params['intr'] = query['query.intr']
    
    # æ—¥ä»˜ç¯„å›²ã®å‡¦ç†
    if 'filter.advanced' in query:
        advanced = query['filter.advanced']
        
        # é–‹å§‹æ—¥ã®ç¯„å›²ã‚’æŠ½å‡º
        start_date_match = re.search(r'AREA\[StartDate\]RANGE\[(.*?),(.*?)\]', advanced)
        if start_date_match:
            start_date = start_date_match.group(1).strip()
            end_date = start_date_match.group(2).strip()
            params['start'] = f"{start_date}_{end_date}"
        
        # å®Œäº†æ—¥ã®ç¯„å›²ã‚’æŠ½å‡º
        comp_date_match = re.search(r'AREA\[CompletionDate\]RANGE\[(.*?),(.*?)\]', advanced)
        if comp_date_match:
            start_date = comp_date_match.group(1).strip()
            end_date = comp_date_match.group(2).strip()
            params['studyComp'] = f"{start_date}_{end_date}"
    
    # è©¦é¨“ã®çŠ¶æ…‹
    if 'filter.overallStatus' in query:
        status = query['filter.overallStatus']
        if isinstance(status, list):
            status = status[0]  # ãƒªã‚¹ãƒˆã®å ´åˆã¯æœ€åˆã®è¦ç´ ã‚’ä½¿ç”¨
        
        status_map = {
            'COMPLETED': 'com',
            'RECRUITING': 'rec',
            'NOT_YET_RECRUITING': 'nyr',
            'ACTIVE_NOT_RECRUITING': 'anr',
            'TERMINATED': 'term',
            'WITHDRAWN': 'wth',
            'SUSPENDED': 'sus'
        }
        
        if status in status_map:
            params['aggFilters'] = f"status:{status_map[status]}"
    
    # ã‚½ãƒ¼ãƒˆé †
    if 'sort' in query:
        sort_options = query['sort']
        if isinstance(sort_options, list) and sort_options:
            if 'LastUpdatePostDate:desc' in sort_options:
                params['sort'] = 'nwst'
    
    encoded_params = urllib.parse.urlencode(params, quote_via=urllib.parse.quote)
    return base_url + encoded_params

def display_results(studies, total_count):
    """æ¤œç´¢çµæœã®è¡¨ç¤ºã¨åŸºæœ¬çš„ãªåˆ†æã‚’è¡Œã†"""
    st.divider()
    st.subheader(f"Total studies found: {total_count}")
    st.write(f"Studies retrieved: {len(studies)}")

    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã¸ã®å¤‰æ›
    df = pd.DataFrame(studies)

    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®è¡¨ç¤º
    st.subheader("å–å¾—ãƒ‡ãƒ¼ã‚¿ã®ä¸€è¦§")
    st.dataframe(df)

    # ãƒ‡ãƒ¼ã‚¿ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    csv = convert_df_to_csv(df)
    st.download_button(
        label="Download as CSV",
        data=csv,
        file_name='structured_clinical_trials.csv',
        mime='text/csv',
    )

    # æ¤œç´¢çµæœä¸€è¦§
    st.subheader("å€‹åˆ¥è©¦é¨“ã®è¦ç´„(Optional)")
    study_options = [f"{study['nct_id']}: {study['title']}" for study in studies if study['title']]
    st.session_state.selected_studies = st.multiselect("è©³ç´°ã‚’ç¢ºèªã—ãŸã„è©¦é¨“ã‚’é¸æŠã—ã¦ãã ã•ã„:", study_options, key='study_selector', default=st.session_state.selected_studies)

    for study_option in st.session_state.selected_studies:
        nct_id = study_option.split(":")[0]
        study = next((s for s in studies if s['nct_id'] == nct_id), None)
        if study:
            st.subheader(f"{study['nct_id']}: {study['title']}")
            st.write(f"**ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹:** {study['status']}")
            st.write(f"**é–‹å§‹æ—¥:** {study['start_date']}")
            st.write(f"**çµ‚äº†æ—¥:** {study['end_date']}")
            st.write("**æ¦‚è¦:**")
            st.write(study['brief_summary'])
            st.write("**ä»‹å…¥å†…å®¹:**")
            st.write(', '.join([intervention['name'] for intervention in study['interventions']]))
            st.write("**ä¸»è¦è©•ä¾¡é …ç›®:**")
            st.write(', '.join(study['outcomes']['primary']))
            st.write("**å‰¯æ¬¡è©•ä¾¡é …ç›®:**")
            st.write(', '.join(study['outcomes']['secondary']))
            st.write("---")
    st.divider()
    st.subheader("å–å¾—ãƒ‡ãƒ¼ã‚¿ã®è¦ç´„")

def analyze_studies(studies, p):
    """
    å–å¾—ã—ãŸè‡¨åºŠè©¦é¨“ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°åˆ†æã‚’å®Ÿè¡Œ
    - ä»‹å…¥ã®åˆ†å¸ƒåˆ†æ
    - è©•ä¾¡é …ç›®ã®åˆ†æ
    - LLMã«ã‚ˆã‚‹è¦ç´„ç”Ÿæˆ
    """
    st.header("çµæœã®è¦ç´„ã¨å¯è¦–åŒ–")

    num_studies = len(studies)

    # ä»‹å…¥ã€é©æ ¼åŸºæº–ã€ã‚¢ã‚¦ãƒˆã‚«ãƒ ã®é›†è¨ˆ
    interventions = [intervention['name'] for study in studies for intervention in study['interventions']]
    eligibility_criteria = [study['eligibility']['criteria'] for study in studies]
    primary_outcomes = [outcome for study in studies for outcome in study['outcomes']['primary']]
    secondary_outcomes = [outcome for study in studies for outcome in study['outcomes']['secondary']]

    # é›†è¨ˆ
    top_interventions = get_top_items(interventions)
    top_eligibility = get_top_items(eligibility_criteria)
    top_primary_outcomes = get_top_items(primary_outcomes)
    top_secondary_outcomes = get_top_items(secondary_outcomes)

    # LLMã‚’ä½¿ç”¨ã—ã¦è¦ç´„æ–‡ã‚’ç”Ÿæˆ
    summary_prompt = SUMMARY_PROMPT_TEMPLATE.format(
        num_studies=num_studies,
        p=p,
        interventions=', '.join([f"{i[0]} ({i[1]}ä»¶)" for i in top_interventions]),
        eligibility=', '.join([f"{e[0][:50]}... ({e[1]}ä»¶)" for e in top_eligibility]),
        primary_outcomes=', '.join([f"{o[0]} ({o[1]}ä»¶)" for o in top_primary_outcomes]),
        secondary_outcomes=', '.join([f"{o[0]} ({o[1]}ä»¶)" for o in top_secondary_outcomes])
    )

    with st.spinner("çµæœã‚’è¦ç´„ä¸­..."):
        response = llm.invoke(summary_prompt)
        summary = response.content

    # å¯è¦–åŒ–
    st.subheader("è©•ä¾¡å¯¾è±¡åŒ»è–¬å“ã®åˆ†å¸ƒ")
    fig1, drug_df = Visualizer.plot_drug_distribution(top_interventions)
    st.pyplot(fig1)

    st.subheader("ä¸»è¦è©•ä¾¡é …ç›®ã®åˆ†å¸ƒ")
    fig2, outcome_df = Visualizer.plot_outcome_distribution(top_primary_outcomes)
    st.pyplot(fig2)

    # çµæœã®å‡ºåŠ›
    st.subheader("å…¨ä½“ã®è¦ç´„")
    st.write(summary)

    st.subheader("Top 5 Evaluated Drugs:")
    st.table(drug_df)

    st.subheader("Top 5 Primary Outcomes:")
    st.table(outcome_df)

    # é¸æŠã•ã‚ŒãŸè©¦é¨“ã®æ¨ªæ–­çš„ãªè¦ç´„
    if st.session_state.selected_studies:
        selected_study_data = [study for study in studies if f"{study['nct_id']}: {study['title']}" in st.session_state.selected_studies]
        cross_study_summaries = [f"""
        ### è©¦é¨“ID: {study['nct_id']}
        - ã‚¿ã‚¤ãƒˆãƒ«: {study['title']}
        - ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {study['status']}
        - é–‹å§‹æ—¥: {study['start_date']}
        - çµ‚äº†æ—¥: {study['end_date']}
        - ä»‹å…¥å†…å®¹: {', '.join([intervention['name'] for intervention in study['interventions']])}
        - ä¸»è¦è©•ä¾¡é …ç›®: {', '.join(study['outcomes']['primary'])}
        - å‰¯æ¬¡è©•ä¾¡é …ç›®: {', '.join(study['outcomes']['secondary'])}
        """ for study in selected_study_data]

        cross_study_prompt = CROSS_STUDY_PROMPT.format(summaries=' '.join(cross_study_summaries))

        with st.spinner("é¸æŠã•ã‚ŒãŸè©¦é¨“ã®æ¨ªæ–­çš„ãªè¦ç´„ã‚’ç”Ÿæˆä¸­..."):
            response = llm.invoke(cross_study_prompt)
            cross_study_summary = response.content

        st.subheader("é¸æŠã•ã‚ŒãŸè©¦é¨“ã®æ¨ªæ–­çš„ãªè¦ç´„")
        st.write(cross_study_summary)

def analyze_eligibility_criteria(studies):
    st.header("é©æ ¼åŸºæº–ã®è©³ç´°åˆ†æ")

    if studies:
        eligibility_criteria = [study['eligibility']['criteria'] for study in studies]

        criteria_prompt = CRITERIA_PROMPT.format(criteria=' '.join(eligibility_criteria))

        with st.spinner("é©æ ¼åŸºæº–ã®åˆ†æã‚’ç”Ÿæˆä¸­..."):
            response = llm.invoke(criteria_prompt)
            criteria_analysis = response.content

        st.write(criteria_analysis)

def summarize_publications(studies):
    st.header("é–¢é€£æ–‡çŒ®ã®è¦ç´„")

    if studies:
        publications = [pub for study in studies for pub in study['publications']]

        if publications:
            publication_summaries = [f"""
            ã‚¿ã‚¤ãƒˆãƒ«: {pub['title']}
            å¼•ç”¨: {pub['citation']}
            PMID: {pub['pmid']}
            """ for pub in publications[:5]]

            publication_prompt = PUBLICATION_PROMPT.format(summaries=' '.join(publication_summaries))

            with st.spinner("é–¢é€£æ–‡çŒ®ã®è¦ç´„ã‚’ç”Ÿæˆä¸­..."):
                response = llm.invoke(publication_prompt)
                publication_analysis = response.content

            st.write(publication_analysis)
        else:
            st.write("é–¢é€£æ–‡çŒ®ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

def compare_studies(studies):
    st.header("è¤‡æ•°ã®è©¦é¨“ã®æ¨ªæ–­çš„ãªæ¯”è¼ƒåˆ†æ")

    if len(studies) >= 2:
        selected_studies = st.multiselect(
            "æ¯”è¼ƒåˆ†æã™ã‚‹è©¦é¨“ã‚’2ã¤ä»¥ä¸Šé¸æŠã—ã¦ãã ã•ã„ï¼š",
            options=[f"{study['nct_id']}: {study['title']}" for study in studies],
            default=[f"{studies[0]['nct_id']}: {studies[0]['title']}",
                    f"{studies[1]['nct_id']}: {studies[1]['title']}"],
            key='comparison_selector'
        )

        if len(selected_studies) >= 2:
            comparison_data = []
            for selected in selected_studies:
                nct_id = selected.split(":")[0].strip()
                study = next((s for s in studies if s['nct_id'] == nct_id), None)
                if study:
                    comparison_data.append(f"""
                    NCT ID: {study['nct_id']}
                    ã‚¿ã‚¤ãƒˆãƒ«: {study['title']}
                    çŠ¶æ…‹: {study['status']}
                    ä»‹å…¥: {', '.join([i['name'] for i in study['interventions']])}
                    ä¸»è¦è©•ä¾¡é …ç›®: {', '.join(study['outcomes']['primary'])}
                    å‰¯æ¬¡è©•ä¾¡é …ç›®: {', '.join(study['outcomes']['secondary'])}
                    é©æ ¼åŸºæº–: {study['eligibility']['criteria']}
                    """)

            comparison_prompt = COMPARISON_PROMPT.format(comparison_data=' '.join(comparison_data))

            with st.spinner("è©¦é¨“ã®æ¯”è¼ƒåˆ†æã‚’ç”Ÿæˆä¸­..."):
                response = llm.invoke(comparison_prompt)
                comparison_analysis = response.content

            st.write(comparison_analysis)
        else:
            st.write("æ¯”è¼ƒã™ã‚‹ã«ã¯2ã¤ä»¥ä¸Šã®è©¦é¨“ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")

def generate_protocol_draft(studies):
    st.header("ãƒ—ãƒ­ãƒˆã‚³ãƒ«ãƒ‰ãƒ©ãƒ•ãƒˆç”Ÿæˆæ”¯æ´")
    st.write("åé›†ã—ãŸæƒ…å ±ã‚’åŸºã«ã€æ–°ã—ã„è‡¨åºŠè©¦é¨“ã®ãƒ—ãƒ­ãƒˆã‚³ãƒ«ãƒ‰ãƒ©ãƒ•ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚")
    
    target_condition = st.text_input("å¯¾è±¡ç–¾æ‚£ï¼š", key='target_condition')
    intervention = st.text_input("ä»‹å…¥æ–¹æ³•ï¼š", key='intervention')
    primary_outcome = st.text_input("ä¸»è¦è©•ä¾¡é …ç›®ï¼š", key='primary_outcome')

    if st.button("ãƒ—ãƒ­ãƒˆã‚³ãƒ«ãƒ‰ãƒ©ãƒ•ãƒˆã‚’ç”Ÿæˆ", key='generate_protocol'):
        existing_studies = [
            f"NCT ID: {s['nct_id']}, ã‚¿ã‚¤ãƒˆãƒ«: {s['title']}, çŠ¶æ…‹: {s['status']}, "
            f"ä»‹å…¥: {', '.join([i['name'] for i in s['interventions']])}, "
            f"ä¸»è¦è©•ä¾¡é …ç›®: {', '.join(s['outcomes']['primary'])}"
            for s in studies[:5]
        ]

        protocol_prompt = PROTOCOL_PROMPT.format(
            target_condition=target_condition,
            intervention=intervention,
            primary_outcome=primary_outcome,
            existing_studies=' '.join(existing_studies)
        )

        with st.spinner("ãƒ—ãƒ­ãƒˆã‚³ãƒ«ãƒ‰ãƒ©ãƒ•ãƒˆã‚’ç”Ÿæˆä¸­..."):
            response = llm.invoke(protocol_prompt)
            protocol_draft = response.content

        st.subheader("ç”Ÿæˆã•ã‚ŒãŸãƒ—ãƒ­ãƒˆã‚³ãƒ«ãƒ‰ãƒ©ãƒ•ãƒˆ")
        st.write(protocol_draft)

if __name__ == "__main__":
    main()